{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "JFFo5k1wI3rg",
        "outputId": "486dee6d-37be-4ea5-cc5f-ec64fea75923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visiting: https://coupangshope.shop/index/user/login.html (Depth 0)\n",
            "Phishing Detection for https://coupangshope.shop/index/user/login.html: Phishing\n",
            "\n",
            "Here's why the website is highly suspicious and likely a phishing site:\n",
            "\n",
            "* **Suspicious URL:** The URL, `https://coupangshope.shop/index/user/login.html`, is very similar to the legitimate Coupang website but includes a misspelling (\"coupangshope\" instead of \"coupang\").  This is a common tactic used by phishers to trick users into believing the site is genuine.\n",
            "\n",
            "* **Non-English Text and Mixed Language:** The website uses a mix of English and Chinese (\"登錄\" means \"login\" in Chinese). This inconsistency is a red flag, as legitimate websites generally stick to one consistent language.\n",
            "\n",
            "* **Poor Website Design:** The HTML structure hints at a hastily put-together website. The use of generic Bootstrap styling and randomly included/commented-out code suggests a lack of professional design, which is common for phishing sites.\n",
            "\n",
            "* **Generic Image:** The inclusion of a generic image (`/upload/74711ca2828d4271/photo_2025-06-04_19-30-15.jpg`) in place of a proper logo further points to a poorly constructed and untrustworthy website.\n",
            "\n",
            "* **\"Loading...\" notification:** The presence of a persistent \"loading...\" notification could be used to distract the user from noticing other red flags or delays in the login process.\n",
            "\n",
            "In summary, the combination of a suspicious URL, inconsistent language, amateur website design, and potentially deceptive loading indicator strongly suggests that this is a phishing attempt designed to steal Coupang user login credentials.  Never enter your login details on a site like this.\n",
            "\n",
            "Visiting: https://coupangshope.shop/index/user/lang (Depth 1)\n",
            "Phishing Detection for https://coupangshope.shop/index/user/lang: Phishing\n",
            "\n",
            "Here's why the website is highly suspicious and likely a phishing site:\n",
            "\n",
            "* **Suspicious URL:** The domain \"coupangshope.shop\" is very similar to the legitimate e-commerce site Coupang, but it's not the official domain.  The addition of \"shope\" is a common tactic to create a look-alike domain.  Legitimate companies rarely use such variations in their official URLs.\n",
            "\n",
            "* **Language Selection Page as a Primary Page:** A language selection page isn't usually the primary or initial page of a legitimate e-commerce site.  It's more likely to be embedded within the site's navigation.  Presenting this as the main page is unusual.\n",
            "\n",
            "* **Use of Vant Framework:** While the use of the Vant framework (a UI component library) isn't inherently malicious, it's often used by developers who may not prioritize security best practices.  It's a red flag in combination with other suspicious elements.\n",
            "\n",
            "* **Inconsistencies in Language Codes:** The provided language codes (`lang` parameters in URLs) contain several errors and inconsistencies. For instance,  `zh-cn` (Simplified Chinese) is listed under the title \"中文繁體\" (Traditional Chinese).  `po-br` is not a valid language code for Portuguese (it should be `pt-br`). These errors suggest a lack of attention to detail, which is typical of phishing sites.  Other codes are similarly incorrect or mismatched with language names.\n",
            "\n",
            "* **Lack of HTTPS:** While not explicitly stated, the lack of \"https://\" in the provided information suggests the site might not be using a secure connection.  This is a major red flag for any site handling personal data.\n",
            "\n",
            "The combination of a suspicious URL, unusual page structure, coding errors, and the potential lack of HTTPS makes this website extremely suspicious.  It's highly probable that this site is designed to steal user credentials or other sensitive information under the guise of being a legitimate Coupang page.\n",
            "\n",
            "Visiting: https://coupangshope.shop/index/user/register (Depth 2)\n",
            "Phishing Detection for https://coupangshope.shop/index/user/register: Phishing\n",
            "\n",
            "Here's why the website is highly suspicious and likely a phishing site:\n",
            "\n",
            "* **URL:** The URL `https://coupangshope.shop/index/user/register` is very similar to the legitimate Coupang URL, but with a crucial difference:  the addition of \"shop\" in \"coupang**shop**e\". This is a common tactic used by phishers to create a deceptively similar-looking URL.  Legitimate businesses rarely use such a clumsy alteration.\n",
            "\n",
            "* **Website Text and HTML:** The repeated \"註冊帳號\" (register account in Chinese) indicates a lack of proper website localization and quality control, which is atypical of a legitimate e-commerce site.  The HTML shows a basic structure with links to Google Fonts and Bootstrap, but the overall structure seems hastily built and lacking in professional design elements.  The `<meta>` tags all contain \"Formosa,\" which seems oddly generic and unrelated to the apparent purpose (a Coupang clone).\n",
            "\n",
            "* **Image:** The absence of an image and the \"Error extracting text from image\" message suggests a potentially problematic image (possibly a poorly designed logo or a missing image altogether) further suggesting unprofessionalism and a possible lack of resources, consistent with a phishing attempt.\n",
            "\n",
            "* **Unprofessional Aspects:** The commented-out sections in the HTML (like the phone number selection and a motivational quote) look hastily put together, more like a quickly-cloned template rather than a carefully designed registration page.\n",
            "\n",
            "In summary, the combination of a slightly altered URL, poor website design, unprofessional HTML, suspicious text repetition, and the generic use of \"Formosa\" strongly suggests that this is a phishing website designed to steal user credentials.  The site is trying to mimic the appearance of Coupang to trick users into entering their information.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import requests\n",
        "import pytesseract\n",
        "from bs4 import BeautifulSoup\n",
        "from google.cloud import vision_v1 as vision\n",
        "from PIL import Image\n",
        "import time\n",
        "from urllib.parse import urlparse, urljoin\n",
        "\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyC6k_EYykry0wV_gnG2sF0d0qiV4FifnMw\")\n",
        "\n",
        "\n",
        "vision_client = vision.ImageAnnotatorClient()\n",
        "\n",
        "# Path to Tesseract OCR (if using locally)\n",
        "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "\n",
        "### 1. Extract Text from Website ###\n",
        "def fetch_website_text(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        return soup.get_text()\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching URL: {e}\"\n",
        "\n",
        "### 2. Extract HTML Structure ###\n",
        "def fetch_html_tags(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        return str(soup)[:5000]  # Limit to 5000 chars for LLM\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching HTML: {e}\"\n",
        "\n",
        "### 3. Extract Text from Screenshot (OCR) ###\n",
        "def extract_text_from_image(image_path):\n",
        "    try:\n",
        "        # Option 1: Using Google Cloud Vision API\n",
        "        with open(image_path, \"rb\") as image_file:\n",
        "            content = image_file.read()\n",
        "        image = vision.Image(content=content)\n",
        "        response = vision_client.text_detection(image=image)\n",
        "        return response.full_text_annotation.text\n",
        "\n",
        "        # Option 2: Using Tesseract OCR (Alternative)\n",
        "        # image = Image.open(image_path)\n",
        "        # return pytesseract.image_to_string(image)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error extracting text from image: {e}\"\n",
        "\n",
        "### 4. Analyze Data with Gemini API ###\n",
        "def analyze_with_gemini(url, website_text, html_tags, screenshot_text):\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following website details and determine if it is a phishing site.\n",
        "    Provide a clear explanation for your decision.\n",
        "\n",
        "    - **URL**: {url}\n",
        "    - **Website Extracted Text**: {website_text[:5000]}\n",
        "    - **HTML Structure (partial)**: {html_tags}\n",
        "    - **Screenshot Extracted Text**: {screenshot_text[:5000]}\n",
        "\n",
        "    Respond with \"Phishing\" or \"Legitimate\" and provide an explanation.\n",
        "    \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text  # Extract text from Gemini response\n",
        "\n",
        "### 5. Run Phishing Detection ###\n",
        "def detect_phishing(url, screenshot_path):\n",
        "    website_text = fetch_website_text(url)\n",
        "    html_tags = fetch_html_tags(url)\n",
        "    screenshot_text = extract_text_from_image(screenshot_path)\n",
        "\n",
        "    result = analyze_with_gemini(url, website_text, html_tags, screenshot_text)\n",
        "    return result\n",
        "\n",
        "### 6. Web Crawler to Crawl Links from a Website ###\n",
        "def fetch_page_links(url):\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        links = [a['href'] for a in soup.find_all('a', href=True)]\n",
        "        return links\n",
        "    except Exception as e:\n",
        "        return f\"Error fetching links from {url}: {e}\"\n",
        "\n",
        "# Function to Crawl and Detect Phishing on Multiple Pages\n",
        "def crawl_and_detect_phishing(start_url, screenshot_path, max_depth=2):\n",
        "    visited = set()\n",
        "    to_visit = [start_url]\n",
        "    depth = 0\n",
        "\n",
        "    while to_visit and depth < max_depth:\n",
        "        url = to_visit.pop(0)\n",
        "        if url not in visited:\n",
        "            visited.add(url)\n",
        "            print(f\"Visiting: {url} (Depth {depth})\")\n",
        "\n",
        "            # Run phishing detection on the current page\n",
        "            result = detect_phishing(url, screenshot_path)\n",
        "            print(f\"Phishing Detection for {url}: {result}\")\n",
        "\n",
        "            # Fetch links and add to the list to visit\n",
        "            links = fetch_page_links(url)\n",
        "            for link in links:\n",
        "                full_url = urljoin(url, link)  # Ensure the link is absolute\n",
        "                if full_url not in visited:\n",
        "                    to_visit.append(full_url)\n",
        "\n",
        "            time.sleep(1)  # Add a delay to avoid overloading the server\n",
        "\n",
        "        depth += 1\n",
        "\n",
        "\n",
        "start_url = \"https://coupangshope.shop/index/user/login.html\"  # Starting URL\n",
        "screenshot_path = \"\"  # Path to the screenshot\n",
        "\n",
        "crawl_and_detect_phishing(start_url, screenshot_path, max_depth=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFfh_ZeSSb0M",
        "outputId": "d7858ebc-a9e0-42d6-bbdc-53b8aea36199"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-cloud-vision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aH2JRHfJh--",
        "outputId": "2267a8de-0d05-4514-da0c-c4e660d5605a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-vision in /usr/local/lib/python3.11/dist-packages (3.10.2)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2025.6.15)\n"
          ]
        }
      ]
    }
  ]
}